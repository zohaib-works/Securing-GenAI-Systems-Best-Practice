{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "467af072-aa86-4d9b-be56-e06262e96b0f",
   "metadata": {},
   "source": [
    "# Common Pitfalls in Generative AI Security\n",
    "\n",
    "## 1. Top Security Mistakes in Generative AI Systems\n",
    "\n",
    "| Mistake                          | Description                                                                 | Real-World Consequence                                      | Prevention Strategy                                      |\n",
    "|----------------------------------|-----------------------------------------------------------------------------|-------------------------------------------------------------|----------------------------------------------------------|\n",
    "| **Data Leakage**                 | Training datasets or logs left publicly accessible (e.g., open S3 buckets)  | Customer PII exposure, GDPR/CCPA fines, reputational loss   | Default-deny storage policies + regular bucket scans     |\n",
    "| **Insufficient Access Control**  | Exposed APIs or admin consoles without authentication                      | Unauthorized model access and prompt injection attacks      | Mandatory MFA + OAuth + scoped API keys                |\n",
    "| **Model Theft**                  | Insecure model endpoints allow unauthorized download of weights            | Loss of proprietary IP and competitive advantage            | Endpoint encryption + IAM conditions + model signing    |\n",
    "| **Adversarial Vulnerability**    | No defense against malicious inputs (prompt injection/jailbreaks       | Harmful, biased, or dangerous outputs                       | Input validation + adversarial training + output filters |\n",
    "| **Weak Encryption Practices**    | Keys stored in code/repos or plaintext in config files                     | Full system compromise once attacker gains any access      | Customer-managed keys (CMEK) + secrets manager only from vault |\n",
    "| **Neglected Patch Management**   | Outdated libraries, frameworks, or container images                       | Exploitation of known CVEs                                  | Automated dependency scanning + immutable deployments   |\n",
    "| **Poor Monitoring & Logging**    | No or incomplete audit trails and anomaly detection                        | Attacks go unnoticed for months                             | Centralized logging + real-time alerts + SIEM integration |\n",
    "| **Regulatory Non-Compliance**    | Missing data residency, deletion, or consent controls                      | Heavy fines (GDPR up to 4% of global revenue)               | Data mapping + automated retention + compliance tooling |\n",
    "\n",
    "## 2. Most Common Cloud Misconfigurations & How to Avoid Them\n",
    "\n",
    "| Misconfiguration                  | Risk Created                                                    | Correct Configuration                                           |\n",
    "|-----------------------------------|-----------------------------------------------------------------|-----------------------------------------------------------------|\n",
    "| Publicly accessible storage       | Anyone on internet can read training data/models                | Block all public access; use signed URLs only when required    |\n",
    "| Over-permissive IAM roles         | One compromised credential grants full account access          | Least-privilege policies + regular permission audits            |\n",
    "| Exposed APIs without auth         | Unlimited model queries, DoS, data exfiltration                 | Enforce OAuth2 / API keys + rate limiting + WAF                 |\n",
    "| Open security groups / ports      | Direct attack surface to training/inference instances          | Default-deny; only required ports; private subnets + bastion    |\n",
    "| Unencrypted data at rest / transit| Eavesdropping and theft of sensitive logs or weights            | Enforce CMEK + TLS 1.3 everywhere                               |\n",
    "| Disabled or incomplete logging    | No visibility during incident response                          | Enable immutable CloudTrail / Audit Logs for all services       |\n",
    "| Default settings left unchanged   | Known vulnerable configurations remain                         | Use CIS benchmarks + automated configuration checks            |\n",
    "| No backup / DR strategy           | Permanent data or service loss after breach or failure          | Automated backups + cross-region replication + tested DR     |\n",
    "\n",
    "## 3. High-Profile Generative AI Breach Patterns (Lessons Learned)\n",
    "\n",
    "| Incident Type                  | Typical Root Cause                                  | Key Lesson                                                     |\n",
    "|--------------------------------|-----------------------------------------------------|----------------------------------------------------------------|\n",
    "| Public model weight exposure   | Misconfigured S3 / GCS bucket permissions           | Never trust “private by default” — always verify with tools    |\n",
    "| Prompt injection → data exfil  | No input sanitization or output filtering           | Treat all user input as untrusted; implement defense-in-depth  |\n",
    "| Insider model theft            | Over-privileged service account                     | Separate duties; require justification for model download      |\n",
    "| Supply-chain attack via library| Unvetted third-party package with backdoor          | SBOM + reproducible builds + signed artifacts                 |\n",
    "| Jailbreak leading to harmful output | Lack of safety classifiers                      | Multi-layer content filters + human-in-the-loop for high risk |\n",
    "\n",
    "## 4. Checklist to Avoid Pitfalls (Deployable Today)\n",
    "\n",
    "- [ ] All storage objects blocked from public access  \n",
    "- [ ] IAM roles reviewed quarterly; no wildcards (*) in policies  \n",
    "- [ ] MFA enforced on all human and root accounts  \n",
    "- [ ] All API endpoints require authentication + rate limiting  \n",
    "- [ ] Encryption enabled by default (at rest & in transit) with CMEK  \n",
    "- [ ] Immutable logging enabled and forwarded to central SIEM  \n",
    "- [ ] Automated vulnerability + dependency scanning in CI/CD  \n",
    "- [ ] Regular red-team / penetration testing of inference endpoints  \n",
    "- [ ] Incident response playbooks specific to model theft and prompt attacks  \n",
    "- [ ] Documented and tested backup/recovery for models and datasets  \n",
    "\n",
    "Implementing these controls systematically eliminates the vast majority of common generative AI security failures seen in production environments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
